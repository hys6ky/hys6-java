insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('100','approx_count_distinct','approx_count_distinct(expr[, relativeSD])','通过HyperLogLog ++返回估计的基数，relativeSD定义允许的最大估计误差','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('101','avg','avg(expr)','返回expr列的平均值','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('102','collect_list','collect_list(expr)','聚合指定字段的值到list','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('103','collect_set','collect_set(expr)','聚合指定字段的值到set','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('104','corr','corr(expr1, expr2)','计算两列的Pearson相关系数','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('105','count','count(*), count(expr), count(DISTINCT expr[, expr...])','计数','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('106','countDistinct','countDistinct','去重计数 SQL中用法select count(distinct class)','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('107','covar_pop','covar_pop(expr1, expr2) ','总体协方差（population covariance）','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('108','covar_samp','covar_samp(expr1, expr2)','样本协方差（sample covariance）','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('109','first','first(expr[, isIgnoreNull])','分组第一个元素','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('110','last','last','分组最后一个元素','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('111','grouping','grouping','','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('112','grouping_id','grouping_id','','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('113','kurtosis','kurtosis(expr)','计算峰态(kurtosis)值','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('114','skewness','skewness','计算偏度(skewness)','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('115','max','max(col)','最大值','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('116','min','min(col）','最小值','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('117','mean','mean(col）','平均值','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('118','stddev','stddev(expr)','即stddev_samp','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('119','stddev_samp','stddev_pop(expr)','样本标准偏差（sample standard deviation）','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('120','stddev_pop','stddev_samp(expr)','总体标准偏差（population standard deviation）','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('121','sum','sum(expr)','求和','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('122','sumDistinct','sumDistinct','非重复值求和 SQL中用法select sum(distinct class)','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('123','var_pop','var_pop(col)','总体方差（population variance）','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('124','var_samp','var_samp(expr)','样本无偏方差（unbiased variance）','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('125','variance','variance(expr)','即var_samp；返回expr列所有数值的样本方差','1','1','1','聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('126','array_contains',' array_contains(Array<T>, value)','如该数组Array<T>包含value返回true，否则返回false','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('127','explode','explode(expr) ','将Array格式的expr分割成多行或者Map格式的expr分割成多行和多列','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('128','explode_outer','','同explode，但当array或map为空或null时，会展开为null。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('129','posexplode','posexplode(ARRAY)','同explode，带位置索引。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('130','posexplode_outer','','同explode_outer，带位置索引。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('131','from_json','','解析JSON字符串为StructType or ArrayType，有多种参数形式，详见文档。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('132','to_json','to_json()','转为json字符串，支持StructType, ArrayType of StructTypes, a MapType or ArrayType of MapTypes。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('133','get_json_object','get_json_object(json_txt, path)','获取指定json路径的json对象字符串。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('134','json_tuple','json_tuple(jsonStr, p1, p2, ..., pn)','获取json中指定字段值。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('135','map_keys','map_keys(Map<K.V>)','返回map的键组成的array','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('136','map_values','map_values(Map<K.V>)','返回map的值组成的array','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('137','size','size(Array<T>)','array 或 map 的长度','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('138','sort_array','sort_array(e: Column, asc: Boolean)','将array中元素排序（自然排序），默认asc。','1','1','1','集合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('139','add_months','add_months(startDate: Column, numMonths: Int)','指定日期添加n月','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('140','date_add','date_add(start: Column, days: Int)','指定日期之后n天: select date_add(‘2018-01-01’,3)','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('141','date_sub','date_sub(start: Column, days: Int)','指定日期之前n天','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('142','datediff','datediff(end: Column, start: Column)','两日期间隔天数','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('143','current_date','current_date()','当前日期','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('144','current_timestamp','current_timestamp()','当前时间戳，TimestampType类型','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('145','date_format','date_format(dateExpr: Column, format: String)','日期格式化','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('146','dayofmonth','dayofmonth(e: Column)','日期在一月中的天数，支持 date/timestamp/string','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('147','dayofyear','dayofyear(e: Column)','日期在一年中的天数， 支持 date/timestamp/string','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('148','weekofyear','weekofyear(e: Column)','日期在一年中的周数， 支持 date/timestamp/string','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('149','from_unixtime','from_unixtime(ut: Column, f: String)','时间戳转字符串格式','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('150','from_utc_timestamp','from_utc_timestamp(ts: Column, tz: String)','时间戳转指定时区时间戳','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('151','to_utc_timestamp','to_utc_timestamp(ts: Column, tz: String)','指定时区时间戳转UTF时间戳','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('152','hour','hour(e: Column)','提取小时值','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('153','minute','minute(e: Column)','提取分钟值','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('154','month','month(e: Column)','提取月份值','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('155','quarter','quarter(e: Column)','提取季度','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('156','second','second(e: Column)','提取秒','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('157','year','year(e: Column)','提取年','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('158','last_day','last_day(e: Column)','指定日期的月末日期','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('159','months_between','months_between(date1: Column, date2: Column)','计算两日期差几个月','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('160','next_day','next_day(date: Column, dayOfWeek: String)','计算指定日期之后的下一个周一、二…，dayOfWeek区分大小写，只接受 “Mon”, “Tue”, “Wed”, “Thu”, “Fri”, “Sat”, “Sun”。','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('161','to_date','to_date(e: Column)','字段类型转为DateType','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('162','trunc','trunc(date: Column, format: String)','日期截断','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('163','unix_timestamp','unix_timestamp(s: Column, p: String)','指定格式的时间字符串转时间戳','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('164','unix_timestamp','unix_timestamp(s: Column)','同上，默认格式为 yyyy-MM-dd HH:mm:ss','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('165','unix_timestamp','unix_timestamp()','当前时间戳(秒),底层实现为unix_timestamp(current_timestamp(), yyyy-MM-dd HH:mm:ss)','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('166','window','window(timeColumn: Column, windowDuration: String, slideDuration: String, startTime: String)','时间窗口函数，将指定时间(TimestampType)划分到窗口','1','1','1','时间函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('167','cos','cos(a)','返回a的余弦值','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('168','sin','sin(a)','求a的正弦值','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('169','tan','tan(a)','返回a的正切值','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('170','sinh','sinh(a)','返回a的双曲余弦值','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('171','tanh','tanh(a)','求a的双曲正弦值','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('172','cosh','cosh(a)','返回a的双曲正切值','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('173','bin','bin(expr)','将long类型转为对应二进制数值的字符串For example, bin(“12”) returns “1100”.','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('174','bround','bround(expr, d)','舍入，使用Decimal的HALF_EVEN模式，v>0.5向上舍入，v< 0.5向下舍入，v0.5向最近的偶数舍入。','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('175','round','round(e: Column, scale: Int)','HALF_UP模式舍入到scale为小数点。v>=0.5向上舍入，v< 0.5向下舍入,即四舍五入。','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('176','ceil','ceil(expr)','向上舍入','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('177','floor','floor','向下舍入','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('178','cbrt','cbrt(expr)','计算给定值的立方根。','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('179','conv','conv(num:Column, fromBase: Int, toBase: Int)','转换数值（字符串）的进制','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('180','log','log(base: Double, a: Column)','logbase(a)log_{base}(a)logbase​(a)','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('181','log','log(a: Column)','loge(a)log_e(a)loge​(a)','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('182','log10','log10(a: Column)','log10(a)log_{10}(a)log10​(a)','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('183','log2','log2(a: Column)','log2(a)log_{2}(a)log2​(a)','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('184','log1p','log1p(a: Column)','loge(a+1)log_{e}(a+1)loge​(a+1)','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('185','pmod','pmod(dividend: Column, divisor: Column)','返回被除数的正值。','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('186','pow','pow(l: Double, r: Column)','rlr^lrl 注意r是列','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('187','pow','pow(l: Column, r: Double)','rlr^lrl 注意l是列','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('188','pow','pow(l: Column, r: Column)','rlr^lrl 注意r,l都是列','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('189','radians','radians(e: Column)','角度转弧度','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('190','rint','rint(e: Column)','返回与参数值最接近且等于一个数学整数的双精度值。','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('191','shiftLeft','shiftLeft(e: Column, numBits: Int)','向左位移','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('192','shiftRight','shiftRight(e: Column, numBits: Int)','向右位移','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('193','shiftRightUnsigned','shiftRightUnsigned(e: Column, numBits: Int)','向右位移（无符号位）','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('194','signum','signum(e: Column)','返回数值正负符号','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('195','sqrt','sqrt(e: Column)','平方根','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('196','hex','hex(column: Column)','转十六进制','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('197','unhex','unhex(column: Column)','逆转十六进制','1','1','1','数学函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('198','crc32','crc32(e: Column)','计算CRC32,返回bigint','1','1','1','混杂misc函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('199','hash','hash(cols: Column*)','计算 hash code，返回int','1','1','1','混杂misc函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('200','md5','md5(e: Column)','计算MD5摘要，返回32位，16进制字符串','1','1','1','混杂misc函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('201','sha1','sha1(e: Column)','计算SHA-1摘要，返回40位，16进制字符串','1','1','1','混杂misc函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('202','sha2','sha2(e: Column, numBits: Int)','计算SHA-1摘要，返回numBits位，16进制字符串。numBits支持224, 256, 384, or 512.','1','1','1','混杂misc函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('204','abs','abs(e: Column)','绝对值','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('205','array','array(cols: Column*)','多列合并为array，cols必须为同类型','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('206','map','map(cols: Column*)','将多列组织为map，输入列必须为（key,value)形式，各列的key/value分别为同一类型。','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('207','bitwiseNOT','bitwiseNOT(e: Column)','Computes bitwise NOT.','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('208','broadcast','broadcast[T](df: Dataset[T]): Dataset[T]','将df变量广播，用于实现broadcast join。如left.join(broadcast(right), “joinKey”)','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('209','coalesce','coalesce(e: Column*)','返回第一个非空值','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('210','col','col(colName: String)','返回colName对应的Column','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('211','column','column(colName: String)','col函数的别名','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('212','expr','expr(expr: String)','解析expr表达式，将返回值存于Column，并返回这个Column。','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('213','greatest','greatest(exprs: Column*)','返回多列中的最大值，跳过Null','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('214','least','least(exprs: Column*)','返回多列中的最小值，跳过Null','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('215','input_file_name','input_file_name()','返回当前任务的文件名 ？？','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('216','isnan','isnan(e: Column)','检查是否NaN（非数值）','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('217','isnull','isnull(e: Column)','检查是否为Null','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('218','lit','lit(literal: Any)','将字面量(literal)创建一个Column','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('219','typedLit','typedLit[T](literal: T)(implicit arg0: scala.reflect.api.JavaUniverse.TypeTag[T])','将字面量(literal)创建一个Column，literal支持 scala types e.g.: List, Seq and Map.','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('220','monotonically_increasing_id','monotonically_increasing_id()','返回单调递增唯一ID，但不同分区的ID不连续。ID为64位整型。','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('221','nanvl','nanvl(col1: Column, col2: Column)','col1为NaN则返回col2','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('222','negate','negate(e: Column)','负数，同df.select( -df(“amount”) )','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('223','not','not(e: Column)','取反，同df.filter( !df(“isActive”) )','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('224','rand','rand()','随机数[0.0, 1.0]','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('225','rand','rand(seed: Long)','随机数[0.0, 1.0]，使用seed种子','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('226','randn','randn()','随机数，从正态分布取','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('227','randn','randn(seed: Long)','同上','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('228','spark_partition_id','spark_partition_id()','返回partition ID','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('229','struct','struct(cols: Column*)','多列组合成新的struct column ？？','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('230','when','when(condition: Column, value: Any)','当condition为true返回value，如people.select(when(people(“gender”) === “male”, 0).when(people(“gender”) === “female”, 1).otherwise(2)) 如果没有otherwise且condition全部没命中，则返回null.','1','1','1','非聚合函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('232','asc','asc(columnName: String)','正序','1','1','1','排序函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('233','asc_nulls_first','asc_nulls_first(columnName: String)','正序，null排最前','1','1','1','排序函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('234','asc_nulls_last','asc_nulls_last(columnName: String)','正序，null排最后','1','1','1','排序函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('235','desc','desc(columnName: String)','逆序 e.g：df.sort(asc(“dept”), desc(“age”))','1','1','1','排序函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('236','desc_nulls_first','desc_nulls_first(columnName: String)','正序，null排最前','1','1','1','排序函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('237','desc_nulls_last','desc_nulls_last(columnName: String)','正序，null排最后','1','1','1','排序函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('239','ascii','ascii(e: Column)','计算第一个字符的ascii码','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('240','base64','base64(e: Column)','base64转码','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('241','unbase64','unbase64(e: Column)','base64解码','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('242','concat','concat(exprs: Column*)','连接多列字符串','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('243','concat_ws','concat_ws(sep: String, exprs: Column*)','使用sep作为分隔符连接多列字符串','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('244','decode','decode(value: Column, charset: String)','解码','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('245','encode','encode(value: Column, charset: String)','转码，charset支持 ‘US-ASCII’, ‘ISO-8859-1’, ‘UTF-8’, ‘UTF-16BE’, ‘UTF-16LE’, ‘UTF-16’。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('246','format_number','format_number(x: Column, d: Int)','格式化‘#,###,###.##’形式的字符串','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('247','format_string','format_string(format: String, arguments: Column*)','将arguments按format格式化，格式为printf-style。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('248','initcap','initcap(e: Column)','单词首字母大写','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('249','lower','lower(e: Column)','转小写','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('250','upper','upper(e: Column)','转大写','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('251','instr','instr(str: Column, substring: String)','substring在str中第一次出现的位置','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('252','length','length(e: Column)','字符串长度','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('253','levenshtein','levenshtein(l: Column, r: Column)','计算两个字符串之间的编辑距离（Levenshtein distance）','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('254','locate','locate(substr: String, str: Column)','substring在str中第一次出现的位置，位置编号从1开始，0表示未找到。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('255','locate','locate(substr: String, str: Column, pos: Int)','同上，但从pos位置后查找。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('256','lpad','lpad(str: Column, len: Int, pad: String)','字符串左填充。用pad字符填充str的字符串至len长度。有对应的rpad，右填充。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('257','ltrim','ltrim(e: Column)','剪掉左边的空格、空白字符，对应有rtrim.','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('258','ltrim','ltrim(e: Column, trimString: String)','剪掉左边的指定字符,对应有rtrim.','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('259','trim','trim(e: Column, trimString: String)','剪掉左右两边的指定字符','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('260','trim','trim(e: Column)','剪掉左右两边的空格、空白字符','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('261','regexp_extract','regexp_extract(e: Column, exp: String, groupIdx: Int)','正则提取匹配的组','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('262','regexp_replace','regexp_replace(e: Column, pattern: Column, replacement: Column)','正则替换匹配的部分，这里参数为列。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('263','regexp_replace','regexp_replace(e: Column, pattern: String, replacement: String)','正则替换匹配的部分','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('264','repeat','repeat(str: Column, n: Int)','将str重复n次返回','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('265','reverse','reverse(str: Column)','将str反转','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('266','soundex','soundex(e: Column)','计算桑迪克斯代码（soundex code）PS:用于按英语发音来索引姓名,发音相同但拼写不同的单词，会映射成同一个码。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('267','split','split(str: Column, pattern: String)','用pattern分割str','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('268','substring','substring(str: Column, pos: Int, len: Int)','在str上截取从pos位置开始长度为len的子字符串。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('269','substring_index','substring_index(str: Column, delim: String, count: Int)','','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('270','translate','translate(src: Column, matchingString: String, replaceString: String)','把src中的matchingString全换成replaceString。','1','1','1','字符串函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('272','callUDF','callUDF(udfName: String, cols: Column*)','调用UDF','1','1','1','UDF函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('273','udf','udf','定义UDF','1','1','1','UDF函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('275','cume_dist','cume_dist()','窗口分区内值的累积分布','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('276','currentRow','currentRow()','返回表示窗口分区中的当前行的特殊框架边界。','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('277','rank','rank()','排名，返回数据项在分组中的排名，排名相等会在名次中留下空位 1,2,2,4。','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('278','dense_rank','dense_rank()','排名，返回数据项在分组中的排名，排名相等会在名次中不会留下空位 1,2,2,3。','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('279','row_number','row_number()','行号，为每条记录返回一个数字 1,2,3,4','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('280','percent_rank','percent_rank()','返回一个窗口分区内行的相对等级(即百分比)。','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('281','lag','lag(e: Column, offset: Int, defaultValue: Any)','偏移当前行之前的行','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('282','lead','lead(e: Column, offset: Int, defaultValue: Any)','返回当前行后偏移行的值','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('283','ntile','ntile(n: Int)','返回一个有序窗口分区中的ntile组id(从1到n)。','1','1','1','窗口函数');
insert into edw_sparksql_gram(esg_id,function_name,function_example,function_desc,is_available,is_udf,is_sparksql,function_classify) values ('284','unboundedFollowing','unboundedFollowing()','返回表示窗口分区中最后一行的特殊框架边界。','1','1','1','窗口函数');

